{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1jrKTTH_LbM",
        "outputId": "75873c1b-dfd2-4e88-e794-e204a0fd0f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=99c7cd52131698f2665fcfbb9c383ea606bde8cdbbff27f6e0610e46c1943bbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wMufiKRE_Tt-"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
        "\n",
        "schema=StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"customer_id\", StringType(), True),\n",
        "    StructField(\"order_date\", DateType(), True),\n",
        "    StructField(\"loaction\", StringType(), True),\n",
        "    StructField(\"source_order\", StringType(), True)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZApVXwopBCPN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iUFPHujgBZyv",
        "outputId": "aa2735cf-18fe-46ce-fdf3-91965fd680fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, customer_id: string, order_date: date, loaction: string, source_order: string]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"aiht_project\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sales_df = spark.read.format(\"csv\").option(\"inferschema\", \"true\").schema(schema).load(\"/content/sales.csv.txt\")\n",
        "\n",
        "display(sales_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJp98Q49DFCB"
      },
      "source": [
        "Deriving year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLbeslOzC4pv"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import year\n",
        "\n",
        "sales_df = sales_df.withColumn(\"order_year\", year(sales_df.order_date))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PPMw_a1CDekz",
        "outputId": "1230c934-f705-4b41-a5f3-68348c3d992f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, customer_id: string, order_date: date, loaction: string, source_order: string, order_year: int, order_month: int, order_quarter: int]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(sales_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "YLPaHSYnDlNe",
        "outputId": "5478d7c4-9bf0-4a68-981f-070111ecaaa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, customer_id: string, order_date: date, loaction: string, source_order: string, order_year: int, order_month: int, order_quarter: int]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
            "|product_id|customer_id|order_date|loaction|source_order|order_year|order_month|order_quarter|\n",
            "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
            "|         1|          A|2023-01-01|   India|      Swiggy|      2023|       2023|         2023|\n",
            "|         2|          A|2022-01-01|   India|      Swiggy|      2022|       2022|         2022|\n",
            "|         2|          A|2023-01-07|   India|      Swiggy|      2023|       2023|         2023|\n",
            "|         3|          A|2023-01-10|   India|  Restaurant|      2023|       2023|         2023|\n",
            "|         3|          A|2022-01-11|   India|      Swiggy|      2022|       2022|         2022|\n",
            "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "display(sales_df)\n",
        "sales_df.show(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsKN-LbuECp8"
      },
      "source": [
        "Menu dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qK3iVEYHENeC",
        "outputId": "7d78208b-f3b7-40d8-cae3-4ba39e1eca4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, product_name: string, price: string]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
        "\n",
        "schema=StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"product_name\", StringType(), True),\n",
        "    StructField(\"price\", StringType(), True),\n",
        "\n",
        "])\n",
        "\n",
        "menu_df = spark.read.format(\"csv\").option(\"inferschema\", \"true\").schema(schema).load(\"/content/menu.csv.txt\")\n",
        "display(menu_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewyl01tcEr4L",
        "outputId": "accc75a0-a8ce-48d4-a7f3-ce4b5d01b91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------+-----+\n",
            "|product_id|product_name|price|\n",
            "+----------+------------+-----+\n",
            "|         1|       PIZZA|  100|\n",
            "|         2|     Chowmin|  150|\n",
            "|         3|    sandwich|  120|\n",
            "|         4|        Dosa|  110|\n",
            "|         5|     Biryani|   80|\n",
            "+----------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "menu_df.show(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP-93VJERYvz"
      },
      "source": [
        "Total amount spent by each customer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "vxjHf4QfFBhB",
        "outputId": "f36a7ca2-328e-43cb-f620-1ba5fae7c718"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[customer_id: string, sum(price): double]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----------+\n",
            "|customer_id|sum(price)|\n",
            "+-----------+----------+\n",
            "|          A|    4260.0|\n",
            "|          B|    4440.0|\n",
            "|          C|    2400.0|\n",
            "|          D|    1200.0|\n",
            "|          E|    2040.0|\n",
            "+-----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_amount_spent =(sales_df.join(menu_df, 'product_id').groupBy('customer_id').agg({'price' : 'sum'}).orderBy('customer_id'))\n",
        "display(total_amount_spent)\n",
        "total_amount_spent.show(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyNM0wLfTnfi"
      },
      "source": [
        "Total amount of sales in each month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "PSR3zS5XT6oM",
        "outputId": "4f46d809-333e-4133-b8c3-827e20a390ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[order_year: int, sum(price): double]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+\n",
            "|order_year|sum(price)|\n",
            "+----------+----------+\n",
            "|      2023|    9990.0|\n",
            "|      2022|    4350.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1 =(sales_df.join(menu_df, 'product_id').groupBy('order_year').agg({'price' : 'sum'}))\n",
        "display(df1)\n",
        "df1.show(n=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFqXnfY8U5Qu"
      },
      "source": [
        "How many times each product purchased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "3306nF7qUJQu",
        "outputId": "0ab32740-cf24-48bd-a339-1262590059ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_id: int, product_name: string, product_count: bigint]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------+-------------+\n",
            "|product_id|product_name|product_count|\n",
            "+----------+------------+-------------+\n",
            "|         3|    sandwich|           48|\n",
            "|         2|     Chowmin|           24|\n",
            "|         1|       PIZZA|           21|\n",
            "|         4|        Dosa|           12|\n",
            "|         5|     Biryani|            6|\n",
            "|         6|       Pasta|            6|\n",
            "+----------+------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import count\n",
        "most_df = (sales_df.join(menu_df,'product_id').groupBy('product_id','product_name').agg(count('product_id').alias('product_count')).orderBy('product_count',ascending=0)\n",
        "\n",
        "           )\n",
        "display(most_df)\n",
        "most_df.show(n=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhQ81wVvWRTr"
      },
      "source": [
        "Top 5 ordered items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "a6tgNVZlV-04",
        "outputId": "7fbe7a6a-9106-4d5b-c30d-c78671172ea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[product_name: string, product_count: bigint]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-------------+\n",
            "|product_name|product_count|\n",
            "+------------+-------------+\n",
            "|    sandwich|           48|\n",
            "|     Chowmin|           24|\n",
            "|       PIZZA|           21|\n",
            "|        Dosa|           12|\n",
            "|     Biryani|            6|\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import count\n",
        "most_df = (sales_df.join(menu_df,'product_id').groupBy('product_id','product_name').agg(count('product_id').alias('product_count')).orderBy('product_count',ascending=0).drop('product_id').limit(5)\n",
        ")\n",
        "\n",
        "display(most_df)\n",
        "most_df.show(n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhDjdpHxX3Y-"
      },
      "source": [
        "Frequency of customer visited to restaurant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "2ox8J8bIX9wR",
        "outputId": "886ba759-a346-42fa-d01a-26a68dbcf5d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[customer_id: string, count(DISTINCT order_date): bigint]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------------------+\n",
            "|customer_id|count(DISTINCT order_date)|\n",
            "+-----------+--------------------------+\n",
            "|          E|                         5|\n",
            "|          B|                         6|\n",
            "|          D|                         1|\n",
            "|          C|                         3|\n",
            "|          A|                         6|\n",
            "+-----------+--------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "freq = (sales_df.filter(sales_df.source_order=='Restaurant').groupBy('customer_id').agg(countDistinct('order_date'))\n",
        "\n",
        "      )\n",
        "display(freq)\n",
        "freq.show(n=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Kxmu8Ebmrf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}